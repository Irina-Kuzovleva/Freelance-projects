{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 66631,
          "databundleVersionId": 8346466,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Существует сервис Chatbot Arena, где разные чат-боты работающие на основе больших языковых моделей (LLM), генерируют ответы на запросы пользователей. Пользователь печатает запрос, два чат-бота предлагают свои ответы, пользователю необходимо выбрать, какой из ответов наиболее подходящий - у первого бота, второго, либо получается ничья - оба бота одинаково справились с ответами/ни один из ботов не дал подходящего ответа.\n",
        "\n",
        "Задача: необходимо разработать модель, которая будет предсказывать, какой чат-бот предпочтут пользователи. Это поможет улучшить взаимодействие чат-ботов с людьми,сделать  их более соответствующими человеческим предпочтениям.\n",
        "\n",
        "Начнем с загрузки необходимых библиотек и открытия тренировочного набора данных."
      ],
      "metadata": {
        "id": "0LO3g0FXvmcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from scipy.sparse import coo_matrix, hstack\n",
        "from scipy import sparse\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:36:56.839724Z",
          "iopub.execute_input": "2024-09-06T10:36:56.840106Z",
          "iopub.status.idle": "2024-09-06T10:36:59.545153Z",
          "shell.execute_reply.started": "2024-09-06T10:36:56.840075Z",
          "shell.execute_reply": "2024-09-06T10:36:59.543828Z"
        },
        "trusted": true,
        "id": "nkoC3AiYHmKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "\n",
        "RANDOM_STATE = 20824"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.128041Z",
          "iopub.execute_input": "2024-09-06T11:22:32.128891Z",
          "iopub.status.idle": "2024-09-06T11:22:32.137068Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.128844Z",
          "shell.execute_reply": "2024-09-06T11:22:32.135826Z"
        },
        "trusted": true,
        "id": "tB-6CV0ZHmKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.177294Z",
          "iopub.execute_input": "2024-09-06T11:22:32.177692Z",
          "iopub.status.idle": "2024-09-06T11:22:33.257150Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.177662Z",
          "shell.execute_reply": "2024-09-06T11:22:33.255984Z"
        },
        "trusted": true,
        "id": "hVyGDkhjHmKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/kaggle/input/lmsys-chatbot-arena/train.csv'\n",
        "test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'\n",
        "\n",
        "df = pd.read_csv(train_path, sep=',')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:36:59.547929Z",
          "iopub.execute_input": "2024-09-06T10:36:59.548609Z",
          "iopub.status.idle": "2024-09-06T10:37:03.717710Z",
          "shell.execute_reply.started": "2024-09-06T10:36:59.548566Z",
          "shell.execute_reply": "2024-09-06T10:37:03.716150Z"
        },
        "trusted": true,
        "id": "ByPjdbamHmKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В тренировочной базе несколько переменных.\n",
        "\n",
        "**model_a, model_b** - модель бота, отвечающего на запрос. Можно выделить 16 наиболее встречающихся модели.\n",
        "\n",
        "**prompt** - запрос, который пишет пользователь.\n",
        "\n",
        "**response_a, response_b** - ответы ботов.\n",
        "\n",
        "**winner_model_a, winner_model_b, winner_tie** - победа бота a, b или ничья.\n",
        "\n",
        "Всего 57477 наблюдения."
      ],
      "metadata": {
        "id": "AnP5Ap71JDCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:37:03.725521Z",
          "iopub.execute_input": "2024-09-06T10:37:03.726272Z",
          "iopub.status.idle": "2024-09-06T10:37:03.755010Z",
          "shell.execute_reply.started": "2024-09-06T10:37:03.726222Z",
          "shell.execute_reply": "2024-09-06T10:37:03.753813Z"
        },
        "trusted": true,
        "id": "rIwA87XgHmKH",
        "outputId": "60c87652-466c-41be-a0fb-7c31e7c23acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим несколько расчетных переменных - длину запроса и ответов ботов, разницу между длиной ответов ботов, отношение длины ответов ботов к длине запрса."
      ],
      "metadata": {
        "id": "QQ6QD2uyHMxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['len_prompt'] = df['prompt'].apply(lambda x: len(x))\n",
        "df['len_a'] = df['response_a'].apply(lambda x: len(x))\n",
        "df['len_b'] = df['response_b'].apply(lambda x: len(x))\n",
        "\n",
        "df['diff_a_b'] = (df['len_a'] - df['len_b']) / (df['len_a'])\n",
        "df['len_a_prompt'] = df['len_a'] / df['len_prompt']\n",
        "df['len_b_prompt'] = df['len_b'] / df['len_prompt']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:37:03.756565Z",
          "iopub.execute_input": "2024-09-06T10:37:03.757813Z",
          "iopub.status.idle": "2024-09-06T10:37:03.869281Z",
          "shell.execute_reply.started": "2024-09-06T10:37:03.757725Z",
          "shell.execute_reply": "2024-09-06T10:37:03.867734Z"
        },
        "trusted": true,
        "id": "U7Q-Ky-bHmKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим библиотеку spaCy для анализа естественного языка."
      ],
      "metadata": {
        "id": "dDvfQmUDISi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy (run in terminal/prompt)\n",
        "import sys\n",
        "!{sys.executable} -m pip install spacy\n",
        "# Download spaCy's  'en' Model\n",
        "!{sys.executable} -m spacy download en_core_web_sm\n",
        "import spacy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:37:03.871100Z",
          "iopub.execute_input": "2024-09-06T10:37:03.871514Z",
          "iopub.status.idle": "2024-09-06T10:38:07.651723Z",
          "shell.execute_reply.started": "2024-09-06T10:37:03.871480Z",
          "shell.execute_reply": "2024-09-06T10:38:07.650420Z"
        },
        "trusted": true,
        "id": "pWMTg4RNHmKK",
        "outputId": "23c4b156-fdf4-424e-c9ed-d917849a45c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connection.py\", line 203, in _new_conn\n    sock = connection.create_connection(\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/opt/conda/lib/python3.10/socket.py\", line 955, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno -3] Temporary failure in name resolution\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 790, in urlopen\n    response = self._make_request(\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 491, in _make_request\n    raise new_e\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 467, in _make_request\n    self._validate_conn(conn)\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 1096, in _validate_conn\n    conn.connect()\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connection.py\", line 611, in connect\n    self.sock = sock = self._new_conn()\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connection.py\", line 210, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x78830fbfb3d0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 844, in urlopen\n    retries = retries.increment(\n  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 515, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x78830fbfb3d0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/spacy/__main__.py\", line 4, in <module>\n    setup_cli()\n  File \"/opt/conda/lib/python3.10/site-packages/spacy/cli/_util.py\", line 87, in setup_cli\n    command(prog_name=COMMAND)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n  File \"/opt/conda/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1688, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n  File \"/opt/conda/lib/python3.10/site-packages/spacy/cli/download.py\", line 44, in download_cli\n    download(model, direct, sdist, *ctx.args)\n  File \"/opt/conda/lib/python3.10/site-packages/spacy/cli/download.py\", line 85, in download\n    compatibility = get_compatibility()\n  File \"/opt/conda/lib/python3.10/site-packages/spacy/cli/download.py\", line 130, in get_compatibility\n    r = requests.get(about.__compatibility__)\n  File \"/opt/conda/lib/python3.10/site-packages/requests/api.py\", line 73, in get\n    return request(\"get\", url, params=params, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/requests/api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x78830fbfb3d0>: Failed to resolve 'raw.githubusercontent.com' ([Errno -3] Temporary failure in name resolution)\"))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:38:07.653307Z",
          "iopub.execute_input": "2024-09-06T10:38:07.654042Z",
          "iopub.status.idle": "2024-09-06T10:38:08.879398Z",
          "shell.execute_reply.started": "2024-09-06T10:38:07.653992Z",
          "shell.execute_reply": "2024-09-06T10:38:08.877866Z"
        },
        "trusted": true,
        "id": "6WSeZ6rEHmKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выделим данные с запросом пользователей (prompt) в отдельную переменную. Для каждого запроса проведем лемматизацию, удаление стоп-слов и удаление символов.  "
      ],
      "metadata": {
        "id": "FSS5g0WCIxI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_prompt = df['prompt'].values\n",
        "corpus_prompt.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:38:08.881269Z",
          "iopub.execute_input": "2024-09-06T10:38:08.881773Z",
          "iopub.status.idle": "2024-09-06T10:38:08.889941Z",
          "shell.execute_reply.started": "2024-09-06T10:38:08.881727Z",
          "shell.execute_reply": "2024-09-06T10:38:08.888824Z"
        },
        "trusted": true,
        "id": "b3vBqtNSHmKL",
        "outputId": "ce401ff4-3a63-4e5c-9ac5-f675b0cf5f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(57477,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for i in range(len(corpus_prompt)):\n",
        "    corpus_prompt[i] = nlp(corpus_prompt[i])\n",
        "    corpus_prompt[i] = [token for token in corpus_prompt[i] if not token.is_stop]\n",
        "    corpus_prompt[i] = \" \".join([token.lemma_ for token in corpus_prompt[i]])\n",
        "    corpus_prompt[i] = re.sub(r\"(?!'``)[\\W\\d]+|(?![\\w])'[^a-zA-Z]\", ' ', corpus_prompt[i]).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:38:08.891231Z",
          "iopub.execute_input": "2024-09-06T10:38:08.891639Z",
          "iopub.status.idle": "2024-09-06T10:45:35.150579Z",
          "shell.execute_reply.started": "2024-09-06T10:38:08.891600Z",
          "shell.execute_reply": "2024-09-06T10:45:35.149301Z"
        },
        "trusted": true,
        "id": "z_rPsxACHmKM",
        "outputId": "326f1ba3-eead-4452-a296-07517614beb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 7min 24s, sys: 1.65 s, total: 7min 25s\nWall time: 7min 26s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "То же самое сделаем для переменной с ответами бота a."
      ],
      "metadata": {
        "id": "UZ3wxgMiJ4al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_a = df['response_a'].values\n",
        "\n",
        "corpus_a.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:45:35.156387Z",
          "iopub.execute_input": "2024-09-06T10:45:35.156885Z",
          "iopub.status.idle": "2024-09-06T10:45:35.164650Z",
          "shell.execute_reply.started": "2024-09-06T10:45:35.156852Z",
          "shell.execute_reply": "2024-09-06T10:45:35.163442Z"
        },
        "trusted": true,
        "id": "sX5Q3fcSHmKN",
        "outputId": "5affb9a7-e9ea-4810-c6e8-3b604317d8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(57477,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for i in range(len(corpus_a)):\n",
        "    corpus_a[i] = nlp(corpus_a[i])\n",
        "    corpus_a[i] = [token for token in corpus_a[i] if not token.is_stop]\n",
        "    corpus_a[i] = \" \".join([token.lemma_ for token in corpus_a[i]])\n",
        "    corpus_a[i] = re.sub(r\"(?!'``)[\\W\\d]+|(?![\\w])'[^a-zA-Z]\", ' ', corpus_a[i]).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T10:45:35.166372Z",
          "iopub.execute_input": "2024-09-06T10:45:35.166752Z",
          "iopub.status.idle": "2024-09-06T11:04:09.741382Z",
          "shell.execute_reply.started": "2024-09-06T10:45:35.166721Z",
          "shell.execute_reply": "2024-09-06T11:04:09.739925Z"
        },
        "trusted": true,
        "id": "eM5aCQkYHmKO",
        "outputId": "3b1d6f3d-2c40-45c0-ae79-bf1bfb96381f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 18min 31s, sys: 842 ms, total: 18min 32s\nWall time: 18min 34s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "То же самое сделаем для переменной с ответами бота b."
      ],
      "metadata": {
        "id": "Q1i84owdKBB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_b = df['response_b'].values\n",
        "\n",
        "corpus_b.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:04:09.743161Z",
          "iopub.execute_input": "2024-09-06T11:04:09.743655Z",
          "iopub.status.idle": "2024-09-06T11:04:09.751570Z",
          "shell.execute_reply.started": "2024-09-06T11:04:09.743612Z",
          "shell.execute_reply": "2024-09-06T11:04:09.750337Z"
        },
        "trusted": true,
        "id": "ZwGhElVjHmKO",
        "outputId": "021eb630-d89b-48de-be95-c6640867bd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(57477,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for i in range(len(corpus_b)):\n",
        "    corpus_b[i] = nlp(corpus_b[i])\n",
        "    corpus_b[i] = [token for token in corpus_b[i] if not token.is_stop]\n",
        "    corpus_b[i] = \" \".join([token.lemma_ for token in corpus_b[i]])\n",
        "    corpus_b[i] = re.sub(r\"(?!'``)[\\W\\d]+|(?![\\w])'[^a-zA-Z]\", ' ', corpus_b[i]).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:04:09.753513Z",
          "iopub.execute_input": "2024-09-06T11:04:09.754117Z",
          "iopub.status.idle": "2024-09-06T11:22:31.146618Z",
          "shell.execute_reply.started": "2024-09-06T11:04:09.754070Z",
          "shell.execute_reply": "2024-09-06T11:22:31.144990Z"
        },
        "trusted": true,
        "id": "L32CHyfLHmKP",
        "outputId": "f08cdc96-07b1-4ef6-805c-6c988d7376e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 18min 19s, sys: 709 ms, total: 18min 20s\nWall time: 18min 21s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соединим обработанные запросы и ответы в один датафрейм. Объединим запрос и два ответа ботов в одну текстовую строку."
      ],
      "metadata": {
        "id": "LT1gFX6NKHFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_prompt = pd.DataFrame(corpus_prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.148771Z",
          "iopub.execute_input": "2024-09-06T11:22:31.149328Z",
          "iopub.status.idle": "2024-09-06T11:22:31.156306Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.149281Z",
          "shell.execute_reply": "2024-09-06T11:22:31.155130Z"
        },
        "trusted": true,
        "id": "2XhMzyMHHmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_a = pd.DataFrame(corpus_a)\n",
        "corpus_b = pd.DataFrame(corpus_b)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.157848Z",
          "iopub.execute_input": "2024-09-06T11:22:31.158225Z",
          "iopub.status.idle": "2024-09-06T11:22:31.169794Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.158186Z",
          "shell.execute_reply": "2024-09-06T11:22:31.168631Z"
        },
        "trusted": true,
        "id": "xRPozcOIHmKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.merge(corpus_prompt, corpus_a, left_index=True, right_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.171445Z",
          "iopub.execute_input": "2024-09-06T11:22:31.171972Z",
          "iopub.status.idle": "2024-09-06T11:22:31.189404Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.171923Z",
          "shell.execute_reply": "2024-09-06T11:22:31.188038Z"
        },
        "trusted": true,
        "id": "Yr0-CpcjHmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.merge(corpus, corpus_b, left_index=True, right_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.191072Z",
          "iopub.execute_input": "2024-09-06T11:22:31.191533Z",
          "iopub.status.idle": "2024-09-06T11:22:31.221931Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.191496Z",
          "shell.execute_reply": "2024-09-06T11:22:31.220627Z"
        },
        "trusted": true,
        "id": "qN2wqyQuHmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.columns = ['prompt', 'a', 'b']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.223526Z",
          "iopub.execute_input": "2024-09-06T11:22:31.223890Z",
          "iopub.status.idle": "2024-09-06T11:22:31.229516Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.223857Z",
          "shell.execute_reply": "2024-09-06T11:22:31.228292Z"
        },
        "trusted": true,
        "id": "De9ULPkTHmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus['all'] = corpus['prompt'] + corpus['a'] + corpus['b']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.231468Z",
          "iopub.execute_input": "2024-09-06T11:22:31.231868Z",
          "iopub.status.idle": "2024-09-06T11:22:31.365679Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.231836Z",
          "shell.execute_reply": "2024-09-06T11:22:31.364297Z"
        },
        "trusted": true,
        "id": "u0WHmGsxHmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_column(row):\n",
        "    if row['winner_model_a'] == 1:\n",
        "        return 0\n",
        "    if row['winner_model_b'] == 1:\n",
        "        return 1\n",
        "    if row['winner_tie'] == 1:\n",
        "        return 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.367294Z",
          "iopub.execute_input": "2024-09-06T11:22:31.367673Z",
          "iopub.status.idle": "2024-09-06T11:22:31.373217Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.367625Z",
          "shell.execute_reply": "2024-09-06T11:22:31.372113Z"
        },
        "trusted": true,
        "id": "HYqvQ_cEHmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus['target'] = df.apply(target_column, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:31.374711Z",
          "iopub.execute_input": "2024-09-06T11:22:31.375151Z",
          "iopub.status.idle": "2024-09-06T11:22:32.057969Z",
          "shell.execute_reply.started": "2024-09-06T11:22:31.375115Z",
          "shell.execute_reply": "2024-09-06T11:22:32.056762Z"
        },
        "trusted": true,
        "id": "Xw-DvXfFHmKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus['len_prompt'] = df['len_prompt']\n",
        "corpus['len_a'] = df['len_a']\n",
        "corpus['len_b'] = df['len_b']\n",
        "corpus['diff_a_b'] = df['diff_a_b']\n",
        "corpus['len_a_prompt'] = df['len_a_prompt']\n",
        "corpus['len_b_prompt'] = df['len_b_prompt']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.059350Z",
          "iopub.execute_input": "2024-09-06T11:22:32.059765Z",
          "iopub.status.idle": "2024-09-06T11:22:32.070677Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.059692Z",
          "shell.execute_reply": "2024-09-06T11:22:32.069260Z"
        },
        "trusted": true,
        "id": "JhmGxUX8HmKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перекодируем целевую переменную из трех столбцов в один. Добавим информацию о длине запроса и ответов."
      ],
      "metadata": {
        "id": "qpVnsuqMKXd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.072189Z",
          "iopub.execute_input": "2024-09-06T11:22:32.072711Z",
          "iopub.status.idle": "2024-09-06T11:22:32.096222Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.072663Z",
          "shell.execute_reply": "2024-09-06T11:22:32.095009Z"
        },
        "trusted": true,
        "id": "Uh7b6peYHmKR",
        "outputId": "bbf8fe61-9eef-41e3-bf39-c29048d9b6e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0   morally right try certain percentage female m...   \n1   difference marriage license marriage certific...   \n2                    explain function call function    \n3   create test set rare category want build clas...   \n4   good way travel tel aviv jerusalem car bus pl...   \n\n                                                   a  \\\n0   question morally right aim certain percentage...   \n1   marriage license legal document allow couple ...   \n2   function call process invoke execute function...   \n3   create test set rare category challenge possi...   \n4   good way travel tel aviv jerusalem depend per...   \n\n                                                   b  \\\n0   ai personal belief opinion tell question gend...   \n1   marriage license marriage certificate differe...   \n2   function call process invoke function program...   \n3   build classifier rare category create test se...   \n4   good way travel tel aviv jerusalem depend per...   \n\n                                                 all  target  len_prompt  \\\n0   morally right try certain percentage female m...       0         165   \n1   difference marriage license marriage certific...       1         200   \n2   explain function call function  function call...       2          60   \n3   create test set rare category want build clas...       0          87   \n4   good way travel tel aviv jerusalem car bus pl...       1          79   \n\n   len_a  len_b  diff_a_b  len_a_prompt  len_b_prompt  \n0   4538   1206  0.734244     27.503030      7.309091  \n1   3114   3649 -0.171805     15.570000     18.245000  \n2    921   1835 -0.992400     15.350000     30.583333  \n3   3182   1562  0.509114     36.574713     17.954023  \n4   1300    772  0.406154     16.455696      9.772152  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>a</th>\n      <th>b</th>\n      <th>all</th>\n      <th>target</th>\n      <th>len_prompt</th>\n      <th>len_a</th>\n      <th>len_b</th>\n      <th>diff_a_b</th>\n      <th>len_a_prompt</th>\n      <th>len_b_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>morally right try certain percentage female m...</td>\n      <td>question morally right aim certain percentage...</td>\n      <td>ai personal belief opinion tell question gend...</td>\n      <td>morally right try certain percentage female m...</td>\n      <td>0</td>\n      <td>165</td>\n      <td>4538</td>\n      <td>1206</td>\n      <td>0.734244</td>\n      <td>27.503030</td>\n      <td>7.309091</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>difference marriage license marriage certific...</td>\n      <td>marriage license legal document allow couple ...</td>\n      <td>marriage license marriage certificate differe...</td>\n      <td>difference marriage license marriage certific...</td>\n      <td>1</td>\n      <td>200</td>\n      <td>3114</td>\n      <td>3649</td>\n      <td>-0.171805</td>\n      <td>15.570000</td>\n      <td>18.245000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>explain function call function</td>\n      <td>function call process invoke execute function...</td>\n      <td>function call process invoke function program...</td>\n      <td>explain function call function  function call...</td>\n      <td>2</td>\n      <td>60</td>\n      <td>921</td>\n      <td>1835</td>\n      <td>-0.992400</td>\n      <td>15.350000</td>\n      <td>30.583333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>create test set rare category want build clas...</td>\n      <td>create test set rare category challenge possi...</td>\n      <td>build classifier rare category create test se...</td>\n      <td>create test set rare category want build clas...</td>\n      <td>0</td>\n      <td>87</td>\n      <td>3182</td>\n      <td>1562</td>\n      <td>0.509114</td>\n      <td>36.574713</td>\n      <td>17.954023</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good way travel tel aviv jerusalem car bus pl...</td>\n      <td>good way travel tel aviv jerusalem depend per...</td>\n      <td>good way travel tel aviv jerusalem depend per...</td>\n      <td>good way travel tel aviv jerusalem car bus pl...</td>\n      <td>1</td>\n      <td>79</td>\n      <td>1300</td>\n      <td>772</td>\n      <td>0.406154</td>\n      <td>16.455696</td>\n      <td>9.772152</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выделим целевую переменную и остальные признаки для построения модели."
      ],
      "metadata": {
        "id": "bI0-peXhTjOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = corpus['target']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.097743Z",
          "iopub.execute_input": "2024-09-06T11:22:32.098115Z",
          "iopub.status.idle": "2024-09-06T11:22:32.107446Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.098085Z",
          "shell.execute_reply": "2024-09-06T11:22:32.106201Z"
        },
        "trusted": true,
        "id": "rpFNYx3SHmKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = corpus[['all', 'len_prompt', 'len_a', 'len_b', 'diff_a_b', 'len_a_prompt', 'len_b_prompt']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.108895Z",
          "iopub.execute_input": "2024-09-06T11:22:32.109332Z",
          "iopub.status.idle": "2024-09-06T11:22:32.126511Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.109293Z",
          "shell.execute_reply": "2024-09-06T11:22:32.125340Z"
        },
        "trusted": true,
        "id": "5sUFI2-hHmKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделим выборку на тренировочную и тестовую (валидационную) в соотношении 80% и 20%."
      ],
      "metadata": {
        "id": "z_Bp-fOaU067"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train, features_test, target_train, target_test \\\n",
        "= train_test_split(features, target, test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:32.138561Z",
          "iopub.execute_input": "2024-09-06T11:22:32.139059Z",
          "iopub.status.idle": "2024-09-06T11:22:32.170211Z",
          "shell.execute_reply.started": "2024-09-06T11:22:32.139017Z",
          "shell.execute_reply": "2024-09-06T11:22:32.168907Z"
        },
        "trusted": true,
        "id": "2FRzwZVbHmKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем текстовую информацию в числовую с помощью CountVectorizer, который считает встречаемость слов в тексте. Не будем учитывать слишком встречающиеся слова, а также очень редкие, они не дадут полезной информации, только будут усложнять анализ."
      ],
      "metadata": {
        "id": "bzJfMf0TV7Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(min_df=0.2, max_df=0.8, ngram_range=(1,3)) #, ngram_range=(1,2))\n",
        "count_vectorizer_fit = count_vectorizer.fit(features_train['all'])\n",
        "features_train_count_vectorizer = count_vectorizer.transform(features_train['all'])\n",
        "features_test_count_vectorizer = count_vectorizer.transform(features_test['all'])\n",
        "\n",
        "print(features_train.shape)\n",
        "print(target_train.shape)\n",
        "print(features_test.shape)\n",
        "print(target_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:22:33.262545Z",
          "iopub.execute_input": "2024-09-06T11:22:33.262997Z",
          "iopub.status.idle": "2024-09-06T11:24:11.951198Z",
          "shell.execute_reply.started": "2024-09-06T11:22:33.262955Z",
          "shell.execute_reply": "2024-09-06T11:24:11.949645Z"
        },
        "trusted": true,
        "id": "e_JzLa3wHmKS",
        "outputId": "bc9e01fb-56b3-459a-aa50-8b00fb03b8ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(45981, 7)\n(45981,)\n(11496, 7)\n(11496,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В результате получается разреженная матрица. Так как есть другие признаки для анализа, кроме текстовых данных, преобразуем переменные, связанные с длиной запроса и ответов, также в разреженную матрицу. Соединим их с текстовой информацией."
      ],
      "metadata": {
        "id": "F8GHY1kXYYAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train_count_vectorizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:11.952838Z",
          "iopub.execute_input": "2024-09-06T11:24:11.953309Z",
          "iopub.status.idle": "2024-09-06T11:24:11.963330Z",
          "shell.execute_reply.started": "2024-09-06T11:24:11.953265Z",
          "shell.execute_reply": "2024-09-06T11:24:11.961706Z"
        },
        "trusted": true,
        "id": "D5H58HROHmKT",
        "outputId": "48fc653c-1b3a-40e7-b209-1886dfa5ef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<45981x26 sparse matrix of type '<class 'numpy.int64'>'\n\twith 317720 stored elements in Compressed Sparse Row format>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_train_other = features_train[['len_prompt', 'len_a', 'len_b', 'diff_a_b', 'len_a_prompt', 'len_b_prompt']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:11.964929Z",
          "iopub.execute_input": "2024-09-06T11:24:11.965344Z",
          "iopub.status.idle": "2024-09-06T11:24:11.979190Z",
          "shell.execute_reply.started": "2024-09-06T11:24:11.965307Z",
          "shell.execute_reply": "2024-09-06T11:24:11.977152Z"
        },
        "trusted": true,
        "id": "H6h_bpXCHmKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = sparse.hstack([features_train_count_vectorizer,features_train_other]).toarray()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:11.980782Z",
          "iopub.execute_input": "2024-09-06T11:24:11.981203Z",
          "iopub.status.idle": "2024-09-06T11:24:12.020760Z",
          "shell.execute_reply.started": "2024-09-06T11:24:11.981161Z",
          "shell.execute_reply": "2024-09-06T11:24:12.019290Z"
        },
        "trusted": true,
        "id": "hMyGvCIhHmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_test_other = features_test[['len_prompt', 'len_a', 'len_b', 'diff_a_b', 'len_a_prompt', 'len_b_prompt']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:12.022644Z",
          "iopub.execute_input": "2024-09-06T11:24:12.023142Z",
          "iopub.status.idle": "2024-09-06T11:24:12.032252Z",
          "shell.execute_reply.started": "2024-09-06T11:24:12.023096Z",
          "shell.execute_reply": "2024-09-06T11:24:12.030918Z"
        },
        "trusted": true,
        "id": "BD6KxCGbHmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_test = sparse.hstack([features_test_count_vectorizer,features_test_other]).toarray()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:12.033988Z",
          "iopub.execute_input": "2024-09-06T11:24:12.034522Z",
          "iopub.status.idle": "2024-09-06T11:24:12.055245Z",
          "shell.execute_reply.started": "2024-09-06T11:24:12.034476Z",
          "shell.execute_reply": "2024-09-06T11:24:12.053939Z"
        },
        "trusted": true,
        "id": "Ws-IU0VyHmKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:12.056989Z",
          "iopub.execute_input": "2024-09-06T11:24:12.057387Z",
          "iopub.status.idle": "2024-09-06T11:24:12.065718Z",
          "shell.execute_reply.started": "2024-09-06T11:24:12.057353Z",
          "shell.execute_reply": "2024-09-06T11:24:12.064354Z"
        },
        "trusted": true,
        "id": "HC6jYuABHmKU",
        "outputId": "06259b8d-130e-4faa-8a24-ea74e16a59a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(45981, 32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для расчета результатов предсказаний используется метрика log loss. Лучшее качество на данной метрике показала модель XGBClassifier. Подберем оптимальные параметры и выведем величину log loss."
      ],
      "metadata": {
        "id": "NnCItFBJZHzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "xgb_model = RandomizedSearchCV(estimator=xgb.XGBClassifier(random_state=RANDOM_STATE), param_distributions={\n",
        "    'n_estimators': range(10, 400),\n",
        "    'learning_rate': [0.01, 0.05],\n",
        "    'subsample': [0.3, 0.9],\n",
        "    'max_depth': range(2, 15),\n",
        "    'colsample_bytree': [0.4, 0.5],\n",
        "    'min_child_weight': range(1, 10)\n",
        "}, scoring='neg_log_loss', random_state=RANDOM_STATE, cv=5)\n",
        "\n",
        "xgb_model_fit = xgb_model.fit(features_train, target_train)\n",
        "xgb_model_log_loss = xgb_model_fit.best_score_\n",
        "\n",
        "print('log_loss, xgb:', abs(xgb_model_log_loss))\n",
        "print('Оптимальные значения параметров:', xgb_model_fit.best_params_)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:24:12.067263Z",
          "iopub.execute_input": "2024-09-06T11:24:12.068296Z",
          "iopub.status.idle": "2024-09-06T11:28:32.765666Z",
          "shell.execute_reply.started": "2024-09-06T11:24:12.068244Z",
          "shell.execute_reply": "2024-09-06T11:28:32.764486Z"
        },
        "trusted": true,
        "id": "moUniYIaHmKU",
        "outputId": "8e74a0a1-4aa5-4b8d-c5ce-279bfd7a7401"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "log_loss, xgb: 1.049803330012377\nОптимальные значения параметров: {'subsample': 0.9, 'n_estimators': 322, 'min_child_weight': 8, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\nCPU times: user 16min 46s, sys: 4.74 s, total: 16min 51s\nWall time: 4min 20s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_predictions = xgb_model.predict_proba(features_test)\n",
        "xgb_log_loss = log_loss(target_test, xgb_predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:32.767107Z",
          "iopub.execute_input": "2024-09-06T11:28:32.767498Z",
          "iopub.status.idle": "2024-09-06T11:28:33.062538Z",
          "shell.execute_reply.started": "2024-09-06T11:28:32.767465Z",
          "shell.execute_reply": "2024-09-06T11:28:33.061197Z"
        },
        "trusted": true,
        "id": "lJlUKjj6HmKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На тестовой (валидационной) выборке значение log loss равно 1.052, что немногим больше, чем на тренировочной. Это показывает, что на результаты модели можно положиться."
      ],
      "metadata": {
        "id": "ttVYCHThhVd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgb_log_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.064254Z",
          "iopub.execute_input": "2024-09-06T11:28:33.065680Z",
          "iopub.status.idle": "2024-09-06T11:28:33.072734Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.065629Z",
          "shell.execute_reply": "2024-09-06T11:28:33.071287Z"
        },
        "trusted": true,
        "id": "tT865o7RHmKW",
        "outputId": "2438c19d-6e3a-4a67-a3ca-70a6f4ba98b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1.0518522450028014\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del features_train\n",
        "del features_test\n",
        "del target_train\n",
        "del target_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.075030Z",
          "iopub.execute_input": "2024-09-06T11:28:33.075722Z",
          "iopub.status.idle": "2024-09-06T11:28:33.086642Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.075672Z",
          "shell.execute_reply": "2024-09-06T11:28:33.085053Z"
        },
        "trusted": true,
        "id": "9V7cZOFpHmKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим тестовую выборку, для которой будем предсказывать, какой из ботов лучше справился с ответом. Всего нам доступно 3 наблюдения."
      ],
      "metadata": {
        "id": "r5GMTR_Hhuby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(test_path, sep=',')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.088352Z",
          "iopub.execute_input": "2024-09-06T11:28:33.089170Z",
          "iopub.status.idle": "2024-09-06T11:28:33.131986Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.089124Z",
          "shell.execute_reply": "2024-09-06T11:28:33.130755Z"
        },
        "trusted": true,
        "id": "SFsmDSVRHmKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['len_prompt'] = df_test['prompt'].apply(lambda x: len(x))\n",
        "df_test['len_a'] = df_test['response_a'].apply(lambda x: len(x))\n",
        "df_test['len_b'] = df_test['response_b'].apply(lambda x: len(x))\n",
        "\n",
        "df_test['diff_a_b'] = (df_test['len_a'] - df_test['len_b']) / (df_test['len_a'])\n",
        "df_test['len_a_prompt'] = df_test['len_a'] / df_test['len_prompt']\n",
        "df_test['len_b_prompt'] = df_test['len_b'] / df_test['len_prompt']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.133638Z",
          "iopub.execute_input": "2024-09-06T11:28:33.134098Z",
          "iopub.status.idle": "2024-09-06T11:28:33.146688Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.134060Z",
          "shell.execute_reply": "2024-09-06T11:28:33.145330Z"
        },
        "trusted": true,
        "id": "Y6n8GJTDHmKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.148234Z",
          "iopub.execute_input": "2024-09-06T11:28:33.149251Z",
          "iopub.status.idle": "2024-09-06T11:28:33.174689Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.149213Z",
          "shell.execute_reply": "2024-09-06T11:28:33.173475Z"
        },
        "trusted": true,
        "id": "SNh3cCwsHmKe",
        "outputId": "d8956ce9-a5e5-4d00-9de4-406758a74806"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  len_prompt  len_a  \\\n0  [\"You still have three oranges. Eating an oran...          86     31   \n1  [\"Mr Reddy and Ms Blue both have valid points ...         488   1457   \n2  [\"To initialize the classification head when p...         217   3984   \n\n   len_b  diff_a_b  len_a_prompt  len_b_prompt  \n0    114 -2.677419      0.360465      1.325581  \n1    460  0.684283      2.985656      0.942623  \n2   3716  0.067269     18.359447     17.124424  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>len_prompt</th>\n      <th>len_a</th>\n      <th>len_b</th>\n      <th>diff_a_b</th>\n      <th>len_a_prompt</th>\n      <th>len_b_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n      <td>86</td>\n      <td>31</td>\n      <td>114</td>\n      <td>-2.677419</td>\n      <td>0.360465</td>\n      <td>1.325581</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n      <td>488</td>\n      <td>1457</td>\n      <td>460</td>\n      <td>0.684283</td>\n      <td>2.985656</td>\n      <td>0.942623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n      <td>217</td>\n      <td>3984</td>\n      <td>3716</td>\n      <td>0.067269</td>\n      <td>18.359447</td>\n      <td>17.124424</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем преобразования, как в тренировочной базе данных, для получения прогноза."
      ],
      "metadata": {
        "id": "2qvKj_cdh_r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_prompt_test = df_test['prompt'].values\n",
        "\n",
        "for i in range(len(corpus_prompt_test)):\n",
        "    corpus_prompt_test[i] = nlp(corpus_prompt_test[i])\n",
        "    corpus_prompt_test[i] = [token for token in corpus_prompt_test[i] if not token.is_stop]\n",
        "    corpus_prompt_test[i] = \" \".join([token.lemma_ for token in corpus_prompt_test[i]])\n",
        "    corpus_prompt_test[i] = re.sub(r\"(?!'``)[\\W\\d]+|(?![\\w])'[^a-zA-Z]\", ' ', corpus_prompt_test[i]).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.176288Z",
          "iopub.execute_input": "2024-09-06T11:28:33.176828Z",
          "iopub.status.idle": "2024-09-06T11:28:33.211648Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.176691Z",
          "shell.execute_reply": "2024-09-06T11:28:33.210385Z"
        },
        "trusted": true,
        "id": "uhA-F2xVHmKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_a_test = df_test['response_a'].values\n",
        "\n",
        "for i in range(len(corpus_a_test)):\n",
        "    corpus_a_test[i] = nlp(corpus_a_test[i])\n",
        "    corpus_a_test[i] = [token for token in corpus_a_test[i] if not token.is_stop]\n",
        "    corpus_a_test[i] = \" \".join([token.lemma_ for token in corpus_a_test[i]])\n",
        "    corpus_a_test[i] = re.sub(r\"(?!'``)[\\W\\d]+|(?![\\w])'[^a-zA-Z]\", ' ', corpus_a_test[i]).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.213043Z",
          "iopub.execute_input": "2024-09-06T11:28:33.213388Z",
          "iopub.status.idle": "2024-09-06T11:28:33.304299Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.213358Z",
          "shell.execute_reply": "2024-09-06T11:28:33.302995Z"
        },
        "trusted": true,
        "id": "ZAPMaSDnHmKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_b_test = df_test['response_b'].values\n",
        "\n",
        "for i in range(len(corpus_b_test)):\n",
        "    corpus_b_test[i] = nlp(corpus_b_test[i])\n",
        "    corpus_b_test[i] = [token for token in corpus_b_test[i] if not token.is_stop]\n",
        "    corpus_b_test[i] = \" \".join([token.lemma_ for token in corpus_b_test[i]])\n",
        "    corpus_b_test[i] = re.sub(r\"(?!'``)[\\W\\d]+|(?![\\w])'[^a-zA-Z]\", ' ', corpus_b_test[i]).lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.305854Z",
          "iopub.execute_input": "2024-09-06T11:28:33.306298Z",
          "iopub.status.idle": "2024-09-06T11:28:33.388920Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.306256Z",
          "shell.execute_reply": "2024-09-06T11:28:33.387743Z"
        },
        "trusted": true,
        "id": "4HRjSd2ZHmKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_prompt_test = pd.DataFrame(corpus_prompt_test)\n",
        "corpus_a_test = pd.DataFrame(corpus_a_test)\n",
        "corpus_b_test = pd.DataFrame(corpus_b_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.390403Z",
          "iopub.execute_input": "2024-09-06T11:28:33.391249Z",
          "iopub.status.idle": "2024-09-06T11:28:33.398190Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.391202Z",
          "shell.execute_reply": "2024-09-06T11:28:33.396901Z"
        },
        "trusted": true,
        "id": "PEA4JMbbHmKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_test = pd.merge(corpus_prompt_test, corpus_a_test, left_index=True, right_index=True)\n",
        "corpus_test = pd.merge(corpus_test, corpus_b_test, left_index=True, right_index=True)\n",
        "corpus_test.columns = ['prompt', 'a', 'b']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.399783Z",
          "iopub.execute_input": "2024-09-06T11:28:33.400747Z",
          "iopub.status.idle": "2024-09-06T11:28:33.413611Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.400698Z",
          "shell.execute_reply": "2024-09-06T11:28:33.412339Z"
        },
        "trusted": true,
        "id": "C0vbLkCCHmKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_test['all'] = corpus_test['prompt'] + corpus_test['a'] + corpus_test['b']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.415506Z",
          "iopub.execute_input": "2024-09-06T11:28:33.415956Z",
          "iopub.status.idle": "2024-09-06T11:28:33.427595Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.415917Z",
          "shell.execute_reply": "2024-09-06T11:28:33.426459Z"
        },
        "trusted": true,
        "id": "qqtq02OrHmKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_test['len_prompt'] = df_test['len_prompt']\n",
        "corpus_test['len_a'] = df_test['len_a']\n",
        "corpus_test['len_b'] = df_test['len_b']\n",
        "corpus_test['diff_a_b'] = df_test['diff_a_b']\n",
        "corpus_test['len_a_prompt'] = df_test['len_a_prompt']\n",
        "corpus_test['len_b_prompt'] = df_test['len_b_prompt']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.429299Z",
          "iopub.execute_input": "2024-09-06T11:28:33.429758Z",
          "iopub.status.idle": "2024-09-06T11:28:33.447169Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.429717Z",
          "shell.execute_reply": "2024-09-06T11:28:33.445990Z"
        },
        "trusted": true,
        "id": "rzicSWQpHmKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_test.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.448997Z",
          "iopub.execute_input": "2024-09-06T11:28:33.449798Z",
          "iopub.status.idle": "2024-09-06T11:28:33.471235Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.449749Z",
          "shell.execute_reply": "2024-09-06T11:28:33.470134Z"
        },
        "trusted": true,
        "id": "mswI-mC6HmKh",
        "outputId": "79624274-aa3d-403d-c199-278c2040d037"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                              prompt  \\\n0          orange today eat orange yesterday orange    \n1   mediator heated political debate oppose party...   \n2   initialize classification head transfer learn...   \n\n                                                   a  \\\n0                                      orange today    \n1   thank share detail situation mediator underst...   \n2   want initialize classification head transfer ...   \n\n                                                   b  \\\n0   orange eat orange yesterday affect number ora...   \n1   mr reddy ms blue valid point argument hand mr...   \n2   initialize classification head perform transf...   \n\n                                                 all  len_prompt  len_a  \\\n0   orange today eat orange yesterday orange  ora...          86     31   \n1   mediator heated political debate oppose party...         488   1457   \n2   initialize classification head transfer learn...         217   3984   \n\n   len_b  diff_a_b  len_a_prompt  len_b_prompt  \n0    114 -2.677419      0.360465      1.325581  \n1    460  0.684283      2.985656      0.942623  \n2   3716  0.067269     18.359447     17.124424  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>a</th>\n      <th>b</th>\n      <th>all</th>\n      <th>len_prompt</th>\n      <th>len_a</th>\n      <th>len_b</th>\n      <th>diff_a_b</th>\n      <th>len_a_prompt</th>\n      <th>len_b_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>orange today eat orange yesterday orange</td>\n      <td>orange today</td>\n      <td>orange eat orange yesterday affect number ora...</td>\n      <td>orange today eat orange yesterday orange  ora...</td>\n      <td>86</td>\n      <td>31</td>\n      <td>114</td>\n      <td>-2.677419</td>\n      <td>0.360465</td>\n      <td>1.325581</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mediator heated political debate oppose party...</td>\n      <td>thank share detail situation mediator underst...</td>\n      <td>mr reddy ms blue valid point argument hand mr...</td>\n      <td>mediator heated political debate oppose party...</td>\n      <td>488</td>\n      <td>1457</td>\n      <td>460</td>\n      <td>0.684283</td>\n      <td>2.985656</td>\n      <td>0.942623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>initialize classification head transfer learn...</td>\n      <td>want initialize classification head transfer ...</td>\n      <td>initialize classification head perform transf...</td>\n      <td>initialize classification head transfer learn...</td>\n      <td>217</td>\n      <td>3984</td>\n      <td>3716</td>\n      <td>0.067269</td>\n      <td>18.359447</td>\n      <td>17.124424</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_submit_count_vectorizer = corpus_test['all']\n",
        "features_submit_count_vectorizer = count_vectorizer.transform(features_submit_count_vectorizer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.472685Z",
          "iopub.execute_input": "2024-09-06T11:28:33.473329Z",
          "iopub.status.idle": "2024-09-06T11:28:33.490937Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.473288Z",
          "shell.execute_reply": "2024-09-06T11:28:33.489761Z"
        },
        "trusted": true,
        "id": "9-QdE7clHmKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_submit_count_vectorizer.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.492255Z",
          "iopub.execute_input": "2024-09-06T11:28:33.493010Z",
          "iopub.status.idle": "2024-09-06T11:28:33.499284Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.492969Z",
          "shell.execute_reply": "2024-09-06T11:28:33.497904Z"
        },
        "trusted": true,
        "id": "7ItIHunaHmKi",
        "outputId": "385e3141-2003-4697-ecea-fae19864403b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(3, 26)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_submit_other = corpus_test[['len_prompt', 'len_a', 'len_b', 'diff_a_b', 'len_a_prompt', 'len_b_prompt']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.500652Z",
          "iopub.execute_input": "2024-09-06T11:28:33.501401Z",
          "iopub.status.idle": "2024-09-06T11:28:33.513827Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.501361Z",
          "shell.execute_reply": "2024-09-06T11:28:33.512591Z"
        },
        "trusted": true,
        "id": "f9damAr8HmKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_submit = sparse.hstack([features_submit_count_vectorizer,features_submit_other]).toarray()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.515322Z",
          "iopub.execute_input": "2024-09-06T11:28:33.515749Z",
          "iopub.status.idle": "2024-09-06T11:28:33.527945Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.515710Z",
          "shell.execute_reply": "2024-09-06T11:28:33.526612Z"
        },
        "trusted": true,
        "id": "7LpDz4s0HmKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем уже настроенную модель XGBClassifier и сделаем предсказания. Оформим результаты в том виде, какой требуется для загрузки."
      ],
      "metadata": {
        "id": "vrkhgZdGiK86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_predictions_submit = xgb_model.predict_proba(features_submit)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.529510Z",
          "iopub.execute_input": "2024-09-06T11:28:33.529955Z",
          "iopub.status.idle": "2024-09-06T11:28:33.552964Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.529911Z",
          "shell.execute_reply": "2024-09-06T11:28:33.551120Z"
        },
        "trusted": true,
        "id": "GdYwtNczHmKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.DataFrame(xgb_predictions_submit)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.555371Z",
          "iopub.execute_input": "2024-09-06T11:28:33.555762Z",
          "iopub.status.idle": "2024-09-06T11:28:33.562317Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.555727Z",
          "shell.execute_reply": "2024-09-06T11:28:33.560900Z"
        },
        "trusted": true,
        "id": "r4sOiPPdHmKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.columns = ['winner_model_a', 'winner_model_b', 'winner_tie']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.564295Z",
          "iopub.execute_input": "2024-09-06T11:28:33.564776Z",
          "iopub.status.idle": "2024-09-06T11:28:33.579583Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.564734Z",
          "shell.execute_reply": "2024-09-06T11:28:33.578349Z"
        },
        "trusted": true,
        "id": "lIiS3mpGHmKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['id'] = df_test['id']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.580961Z",
          "iopub.execute_input": "2024-09-06T11:28:33.581558Z",
          "iopub.status.idle": "2024-09-06T11:28:33.593849Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.581525Z",
          "shell.execute_reply": "2024-09-06T11:28:33.592926Z"
        },
        "trusted": true,
        "id": "MClOspJVHmKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = sample_submission[['id'] + [x for x in sample_submission.columns if x != 'id']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.595217Z",
          "iopub.execute_input": "2024-09-06T11:28:33.595796Z",
          "iopub.status.idle": "2024-09-06T11:28:33.606549Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.595763Z",
          "shell.execute_reply": "2024-09-06T11:28:33.605501Z"
        },
        "trusted": true,
        "id": "BYs2aXguHmKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.608138Z",
          "iopub.execute_input": "2024-09-06T11:28:33.609883Z",
          "iopub.status.idle": "2024-09-06T11:28:33.630134Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.609836Z",
          "shell.execute_reply": "2024-09-06T11:28:33.628946Z"
        },
        "trusted": true,
        "id": "SGxiWsu8HmKk",
        "outputId": "1e89d360-c9b2-4080-f2b8-d82c0a4fb61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 59,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.251833        0.278688    0.469479\n1   211333        0.408196        0.277460    0.314343\n2  1233961        0.383100        0.306598    0.310303",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.251833</td>\n      <td>0.278688</td>\n      <td>0.469479</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.408196</td>\n      <td>0.277460</td>\n      <td>0.314343</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>0.383100</td>\n      <td>0.306598</td>\n      <td>0.310303</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T11:28:33.631671Z",
          "iopub.execute_input": "2024-09-06T11:28:33.632956Z",
          "iopub.status.idle": "2024-09-06T11:28:33.647769Z",
          "shell.execute_reply.started": "2024-09-06T11:28:33.632907Z",
          "shell.execute_reply": "2024-09-06T11:28:33.646238Z"
        },
        "trusted": true,
        "id": "Jya3VdIHHmKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итоговая метрика на тестовой выборке 1.053. На закрытой части тестовой выборки (Private Score) - на основе которой рассчитывались призовые места - 1.088. Метрика участника, занявшего первое место в соревновании - 0.969.\n",
        "\n",
        "**Вывод:** для прогнозирования предпочтений пользователей была проанализирована текстовая информация и числовые данные. Текстовые данные обработаны (проведена лемматизация, очистка текста от стоп-слов, удаление символов) и приведены к числовому виду (с помощью CountVectorizer). Числовые данные - характеристики длины текстовых запросов и ответов.\n",
        "\n",
        "С помощью RandomizedSearchCV были подобраны оптимальные параметры модели XGBClassifier на метрике log loss.\n",
        "\n",
        "Без использования нейросетей получилось добиться достаточно высокого качества предсказания за сравнительно небольшое количество времени. При подготовке модели бОльшую часть времени заняла обработка текстовых данных (43 минуты), подбор гиперпараметров - 4 минуты."
      ],
      "metadata": {
        "id": "5n_ju_WXjQRR"
      }
    }
  ]
}